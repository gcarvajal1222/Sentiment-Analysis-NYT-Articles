---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

#Loading Nessesary libraries for sentiment Analysis
```{r}
library(sentimentr)
library(qdap)
library(jsonlite)
library(dplyr)
library(ggplot2)
library(tm)
library(tidyverse)
library(SentimentAnalysis)
library(quanteda)
library(xlsx)




```


```{r}
result_all_dfs_copy <-result_all_dfs
```



```{r}

#Getting rid of white spaces
#verify that this is right

result_all_dfs_copy$response.docs.lead_paragraph <-(str_squish(result_all_dfs_copy$response.docs.lead_paragraph))
```






#Add Id variable to the NYTSearch_OnlyNews 
```{r}
allNYTSearch_OnlyNews$id <- seq.int(nrow(allNYTSearch_OnlyNews))
```



#Convert datarame into term document matrix from the allNYTSearch_onlyNews
```{r}
myCorpus <- Corpus(VectorSource(result_all_dfs_copy$response.docs.lead_paragraph))
dtm_NYTArticles <-  DocumentTermMatrix(myCorpus, 
                                   control = 
                                     list(removePunctuation = TRUE,
                                          stopwords = TRUE,
                                          tolower = TRUE,
              
                                          removeNumbers = TRUE)) 
```





#tidy format sentiment analysis
```{r}
library(dplyr)
library(tidytext)
ap_td <- tidy(dtm_NYTArticles)
```

#Sentiment from the tdm created above with tidyverse
```{r}
ap_sentiments <- ap_td %>%
  inner_join(get_sentiments("bing"), by = c(term = "word"))
```
#Sentiment from SentimentAnalysis package with LM dicctionary

```{r}
sentiment_scoreLM_cleancode<- analyzeSentiment(dtm_NYTArticles,
                              rules=list("SentimentLM"=list(ruleSentiment, loadDictionaryLM())))
```
#Sentiment from SentimentAnalysis package with GI dicctionary


```{r}
sentiment_scoreGI_cleancode<- analyzeSentiment(dtm_NYTArticles,
                              rules=list("SentimentGI"=list(ruleSentiment, loadDictionaryGI())))


```

#Sentiment from SentimentAnalysis package from qdap dicctionary

```{r}
sentiment_scoreQDAP_cleancode<- (analyzeSentiment(dtm_NYTArticles)$SentimentQDAP)
sentiment_scoreQDAP_DF<-as.data.frame(sentiment_scoreQDAP_cleancode)
```


#putting the dicctionaries in dataframe
```{r}

LM_positive<-list((str(DictionaryLM[["negative"]])))
LM_negative <-list((str(DictionaryLM[["positive"]])))
LM_uncertantity <-list((str(DictionaryLM[["uncertainty"]])))

LM_dicctionary <- do.call(rbind, Map(data.frame, A=LM_positive, B=LM_negative, LM_uncertantity))

```


#combininig 3 sentiment analysis datasets

```{r}
all_sentiment_DF <- cbind(sentiment_scoreLM_cleancode,sentiment_scoreGI_cleancode,sentiment_scoreQDAP_DF)
```

#plotting sentiments
```{r}
library(Hmisc)
hist.data.frame(all_sentiment_DF)
```




WORD CLOUD
```{r}
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
```



#Only run this for word cloud purposes
```{r}
dtm_NYTArticles_word_cloud <-  TermDocumentMatrix(myCorpus, 
                                   control = 
                                     list(removePunctuation = TRUE,
                                          stopwords = TRUE,
                                          tolower = TRUE,
              
                                          removeNumbers = TRUE)) 
m <- as.matrix(dtm_NYTArticles_word_cloud)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
N <- 1

newd<-d[-(1:N), , drop = FALSE]
```

```{r}
set.seed(1234)
wordcloud(words = newd$word, freq = d$freq, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
