nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages_extract[[i+1]] <- nytSearch
Sys.sleep(30) #change to 5 to test on smaller datasets, 30 for actual execution
}
allNYTSearch_try <- rbind_pages(pages_extract)
View(allNYTSearch_try)
allNYTSearch_try2008_10_14 <- rbind_pages(pages_extract)
# Let's set some parameters
#term <- "immigrant+immigration" # Need to use + to string together separate words however it is concatinating
begin_date <- "20081014"
end_date <- "20091201"
oldest <- "oldest"
newest_var<-"newest"
article <- "article"
news <- "News"
#glocations <- "U.S"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?fq=lead_paragraph:(migrant OR immigration OR immigrant OR migration OR refugee OR alien OR undocumented OR asylum) AND type_of_material:news ","&sort=",oldest,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",NYTIMES_KEY, sep=" ")
initialQuery <- fromJSON(baseurl)
# Let's set some parameters
#term <- "immigrant+immigration" # Need to use + to string together separate words however it is concatinating
begin_date <- "20081014"
end_date <- "20091201"
oldest <- "oldest"
newest_var<-"newest"
article <- "article"
news <- "News"
#glocations <- "U.S"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?fq=lead_paragraph:(migrant OR immigration OR immigrant OR migration OR refugee OR alien OR undocumented OR asylum) AND type_of_material:news ","&sort=",oldest,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",NYTIMES_KEY, sep=" ")
initialQuery <- fromJSON(baseurl)
# Let's set some parameters
#term <- "immigrant+immigration" # Need to use + to string together separate words however it is concatinating
begin_date <- "20081014"
end_date <- "20091201"
oldest <- "oldest"
newest_var<-"newest"
article <- "article"
news <- "News"
#glocations <- "U.S"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?fq=lead_paragraph:(migrant OR immigration OR immigrant OR migration OR refugee OR alien OR undocumented OR asylum) AND type_of_material:news ","&sort=",oldest,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",NYTIMES_KEY, sep=" ")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
#require(reshape2)
pages_extract <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages_extract[[i+1]] <- nytSearch
Sys.sleep(30) #change to 5 to test on smaller datasets, 30 for actual execution
}
allNYTSearch_try <- rbind_pages(pages_extract)
View(allNYTSearch_try)
allNYTSearch_try2009_11_23 <- rbind_pages(pages_extract)
# Let's set some parameters
#term <- "immigrant+immigration" # Need to use + to string together separate words however it is concatinating
begin_date <- "20091123"
end_date <- "20101201"
oldest <- "oldest"
newest_var<-"newest"
article <- "article"
news <- "News"
#glocations <- "U.S"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?fq=lead_paragraph:(migrant OR immigration OR immigrant OR migration OR refugee OR alien OR undocumented OR asylum) AND type_of_material:news ","&sort=",oldest,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",NYTIMES_KEY, sep=" ")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
# Let's set some parameters
#term <- "immigrant+immigration" # Need to use + to string together separate words however it is concatinating
begin_date <- "20091123"
end_date <- "20111201"
oldest <- "oldest"
newest_var<-"newest"
article <- "article"
news <- "News"
#glocations <- "U.S"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?fq=lead_paragraph:(migrant OR immigration OR immigrant OR migration OR refugee OR alien OR undocumented OR asylum) AND type_of_material:news ","&sort=",oldest,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",NYTIMES_KEY, sep=" ")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
#require(reshape2)
pages_extract <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages_extract[[i+1]] <- nytSearch
Sys.sleep(30) #change to 5 to test on smaller datasets, 30 for actual execution
}
allNYTSearch_try <- rbind_pages(pages_extract)
View(allNYTSearch_try)
allNYTSearch_try2010_04_30 <- rbind_pages(pages_extract)
result<-do.call("rbind", list(allNYTSearch_try_1982_06_27,allNYTSearch_try_1984_10_26,allNYTSearch_try_1985_06_02))
# Let's set some parameters
#term <- "immigrant+immigration" # Need to use + to string together separate words however it is concatinating
begin_date <- "20100430"
end_date <- "20111201"
oldest <- "oldest"
newest_var<-"newest"
article <- "article"
news <- "News"
#glocations <- "U.S"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?fq=lead_paragraph:(migrant OR immigration OR immigrant OR migration OR refugee OR alien OR undocumented OR asylum) AND type_of_material:news ","&sort=",oldest,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",NYTIMES_KEY, sep=" ")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
View(allNYTSearch_try2010_04_30)
# Let's set some parameters
#term <- "immigrant+immigration" # Need to use + to string together separate words however it is concatinating
begin_date <- "20100430"
end_date <- "20111201"
oldest <- "oldest"
newest_var<-"newest"
article <- "article"
news <- "News"
#glocations <- "U.S"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?fq=lead_paragraph:(migrant OR immigration OR immigrant OR migration OR refugee OR alien OR undocumented OR asylum) AND type_of_material:news ","&sort=",oldest,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",NYTIMES_KEY, sep=" ")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
#require(reshape2)
pages_extract <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages_extract[[i+1]] <- nytSearch
Sys.sleep(30) #change to 5 to test on smaller datasets, 30 for actual execution
}
NYTIMES_KEY="a0HA3uBISDkGyvUGR3FeoAGybtDVPPM5"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?fq=lead_paragraph:(migrant OR immigration OR immigrant OR migration OR refugee OR alien OR undocumented OR asylum) AND type_of_material:news ","&sort=",oldest,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",NYTIMES_KEY, sep=" ")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
#require(reshape2)
pages_extract <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages_extract[[i+1]] <- nytSearch
Sys.sleep(30) #change to 5 to test on smaller datasets, 30 for actual execution
}
allNYTSearch_try <- rbind_pages(pages_extract)
View(allNYTSearch_try)
allNYTSearch_try20111201 <- rbind_pages(pages_extract)
allNYTSearch_try2011_12_01 <- rbind_pages(pages_extract)
# Let's set some parameters
#term <- "immigrant+immigration" # Need to use + to string together separate words however it is concatinating
begin_date <- "20111201"
end_date <- "20131201"
oldest <- "oldest"
newest_var<-"newest"
article <- "article"
news <- "News"
#glocations <- "U.S"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?fq=lead_paragraph:(migrant OR immigration OR immigrant OR migration OR refugee OR alien OR undocumented OR asylum) AND type_of_material:news ","&sort=",oldest,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",NYTIMES_KEY, sep=" ")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
# Let's set some parameters
#term <- "immigrant+immigration" # Need to use + to string together separate words however it is concatinating
begin_date <- "20111201"
end_date <- "20121201"
oldest <- "oldest"
newest_var<-"newest"
article <- "article"
news <- "News"
#glocations <- "U.S"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?fq=lead_paragraph:(migrant OR immigration OR immigrant OR migration OR refugee OR alien OR undocumented OR asylum) AND type_of_material:news ","&sort=",oldest,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",NYTIMES_KEY, sep=" ")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
# Let's set some parameters
#term <- "immigrant+immigration" # Need to use + to string together separate words however it is concatinating
begin_date <- "20111201"
end_date <- "20130601"
oldest <- "oldest"
newest_var<-"newest"
article <- "article"
news <- "News"
#glocations <- "U.S"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?fq=lead_paragraph:(migrant OR immigration OR immigrant OR migration OR refugee OR alien OR undocumented OR asylum) AND type_of_material:news ","&sort=",oldest,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",NYTIMES_KEY, sep=" ")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
#require(reshape2)
pages_extract <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages_extract[[i+1]] <- nytSearch
Sys.sleep(30) #change to 5 to test on smaller datasets, 30 for actual execution
}
allNYTSearch_try <- rbind_pages(pages_extract)
View(allNYTSearch_try)
allNYTSearch_try2013_06_01 <- rbind_pages(pages_extract)
# Let's set some parameters
#term <- "immigrant+immigration" # Need to use + to string together separate words however it is concatinating
begin_date <- "20130601"
end_date <- "20150601"
oldest <- "oldest"
newest_var<-"newest"
article <- "article"
news <- "News"
#glocations <- "U.S"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?fq=lead_paragraph:(migrant OR immigration OR immigrant OR migration OR refugee OR alien OR undocumented OR asylum) AND type_of_material:news ","&sort=",oldest,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",NYTIMES_KEY, sep=" ")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
# Let's set some parameters
#term <- "immigrant+immigration" # Need to use + to string together separate words however it is concatinating
begin_date <- "20130601"
end_date <- "20150101"
oldest <- "oldest"
newest_var<-"newest"
article <- "article"
news <- "News"
#glocations <- "U.S"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?fq=lead_paragraph:(migrant OR immigration OR immigrant OR migration OR refugee OR alien OR undocumented OR asylum) AND type_of_material:news ","&sort=",oldest,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",NYTIMES_KEY, sep=" ")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
#require(reshape2)
pages_extract <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages_extract[[i+1]] <- nytSearch
Sys.sleep(30) #change to 5 to test on smaller datasets, 30 for actual execution
}
allNYTSearch_try <- rbind_pages(pages_extract)
View(allNYTSearch_try)
allNYTSearch_try2014_12_10 <- rbind_pages(pages_extract)
# Let's set some parameters
#term <- "immigrant+immigration" # Need to use + to string together separate words however it is concatinating
begin_date <- "20141210"
end_date <- "20161201"
oldest <- "oldest"
newest_var<-"newest"
article <- "article"
news <- "News"
#glocations <- "U.S"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?fq=lead_paragraph:(migrant OR immigration OR immigrant OR migration OR refugee OR alien OR undocumented OR asylum) AND type_of_material:news ","&sort=",oldest,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",NYTIMES_KEY, sep=" ")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
# Let's set some parameters
#term <- "immigrant+immigration" # Need to use + to string together separate words however it is concatinating
begin_date <- "20141210"
end_date <- "20151201"
oldest <- "oldest"
newest_var<-"newest"
article <- "article"
news <- "News"
#glocations <- "U.S"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?fq=lead_paragraph:(migrant OR immigration OR immigrant OR migration OR refugee OR alien OR undocumented OR asylum) AND type_of_material:news ","&sort=",oldest,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",NYTIMES_KEY, sep=" ")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
#require(reshape2)
pages_extract <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages_extract[[i+1]] <- nytSearch
Sys.sleep(30) #change to 5 to test on smaller datasets, 30 for actual execution
}
allNYTSearch_try <- rbind_pages(pages_extract)
View(allNYTSearch_try)
allNYTSearch_try2015_11_11 <- rbind_pages(pages_extract)
View(allNYTSearch_try_1982_06_27)
# Let's set some parameters
#term <- "immigrant+immigration" # Need to use + to string together separate words however it is concatinating
begin_date <- "20151111"
end_date <- "20161201"
oldest <- "oldest"
newest_var<-"newest"
article <- "article"
news <- "News"
#glocations <- "U.S"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?fq=lead_paragraph:(migrant OR immigration OR immigrant OR migration OR refugee OR alien OR undocumented OR asylum) AND type_of_material:news ","&sort=",oldest,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",NYTIMES_KEY, sep=" ")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
View(allNYTSearch_try)
# Let's set some parameters
#term <- "immigrant+immigration" # Need to use + to string together separate words however it is concatinating
begin_date <- "20151111"
end_date <- "20161201"
oldest <- "oldest"
newest_var<-"newest"
article <- "article"
news <- "News"
#glocations <- "U.S"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?fq=lead_paragraph:(migrant OR immigration OR immigrant OR migration OR refugee OR alien OR undocumented OR asylum) AND type_of_material:news ","&sort=",oldest,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",NYTIMES_KEY, sep=" ")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
#require(reshape2)
pages_extract <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages_extract[[i+1]] <- nytSearch
Sys.sleep(30) #change to 5 to test on smaller datasets, 30 for actual execution
}
allNYTSearch_try <- rbind_pages(pages_extract)
View(allNYTSearch_try)
allNYTSearch_try2016_06_16 <- rbind_pages(pages_extract)
# Let's set some parameters
#term <- "immigrant+immigration" # Need to use + to string together separate words however it is concatinating
begin_date <- "20160616"
end_date <- "20171201"
oldest <- "oldest"
newest_var<-"newest"
article <- "article"
news <- "News"
#glocations <- "U.S"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?fq=lead_paragraph:(migrant OR immigration OR immigrant OR migration OR refugee OR alien OR undocumented OR asylum) AND type_of_material:news ","&sort=",oldest,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",NYTIMES_KEY, sep=" ")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
# Let's set some parameters
#term <- "immigrant+immigration" # Need to use + to string together separate words however it is concatinating
begin_date <- "20160616"
end_date <- "20171201"
oldest <- "oldest"
newest_var<-"newest"
article <- "article"
news <- "News"
#glocations <- "U.S"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?fq=lead_paragraph:(migrant OR immigration OR immigrant OR migration OR refugee OR alien OR undocumented OR asylum) AND type_of_material:news ","&sort=",oldest,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",NYTIMES_KEY, sep=" ")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
#require(reshape2)
pages_extract <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages_extract[[i+1]] <- nytSearch
Sys.sleep(30) #change to 5 to test on smaller datasets, 30 for actual execution
}
allNYTSearch_try <- rbind_pages(pages_extract)
View(allNYTSearch_try)
allNYTSearch_try2017_01_26 <- rbind_pages(pages_extract)
# Let's set some parameters
#term <- "immigrant+immigration" # Need to use + to string together separate words however it is concatinating
begin_date <- "20170126"
end_date <- "20181201"
oldest <- "oldest"
newest_var<-"newest"
article <- "article"
news <- "News"
#glocations <- "U.S"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?fq=lead_paragraph:(migrant OR immigration OR immigrant OR migration OR refugee OR alien OR undocumented OR asylum) AND type_of_material:news ","&sort=",oldest,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",NYTIMES_KEY, sep=" ")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
# Let's set some parameters
#term <- "immigrant+immigration" # Need to use + to string together separate words however it is concatinating
begin_date <- "20170126"
end_date <- "20180601"
oldest <- "oldest"
newest_var<-"newest"
article <- "article"
news <- "News"
#glocations <- "U.S"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?fq=lead_paragraph:(migrant OR immigration OR immigrant OR migration OR refugee OR alien OR undocumented OR asylum) AND type_of_material:news ","&sort=",oldest,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",NYTIMES_KEY, sep=" ")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
#require(reshape2)
pages_extract <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages_extract[[i+1]] <- nytSearch
Sys.sleep(30) #change to 5 to test on smaller datasets, 30 for actual execution
}
allNYTSearch_try <- rbind_pages(pages_extract)
View(allNYTSearch_try)
allNYTSearch_try2017_09_19 <- rbind_pages(pages_extract)
# Let's set some parameters
#term <- "immigrant+immigration" # Need to use + to string together separate words however it is concatinating
begin_date <- "20170919"
end_date <- "20181201"
oldest <- "oldest"
newest_var<-"newest"
article <- "article"
news <- "News"
#glocations <- "U.S"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?fq=lead_paragraph:(migrant OR immigration OR immigrant OR migration OR refugee OR alien OR undocumented OR asylum) AND type_of_material:news ","&sort=",oldest,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",NYTIMES_KEY, sep=" ")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
#require(reshape2)
pages_extract <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages_extract[[i+1]] <- nytSearch
Sys.sleep(30) #change to 5 to test on smaller datasets, 30 for actual execution
}
allNYTSearch_try <- rbind_pages(pages_extract)
View(allNYTSearch_try)
allNYTSearch_try2018_11_30 <- rbind_pages(pages_extract)
# Let's set some parameters
#term <- "immigrant+immigration" # Need to use + to string together separate words however it is concatinating
begin_date <- "20181130"
end_date <- "20200101"
oldest <- "oldest"
newest_var<-"newest"
article <- "article"
news <- "News"
#glocations <- "U.S"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?fq=lead_paragraph:(migrant OR immigration OR immigrant OR migration OR refugee OR alien OR undocumented OR asylum) AND type_of_material:news ","&sort=",oldest,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",NYTIMES_KEY, sep=" ")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
#require(reshape2)
pages_extract <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages_extract[[i+1]] <- nytSearch
Sys.sleep(30) #change to 5 to test on smaller datasets, 30 for actual execution
}
allNYTSearch_try <- rbind_pages(pages_extract)
View(allNYTSearch_try)
allNYTSearch_try2019_12_31 <- rbind_pages(pages_extract)
result_all_dfs<-do.call("rbind", list(allNYTSearch_try_1982_06_27,allNYTSearch_try_1984_10_26,allNYTSearch_try_1985_06_02,allNYTSearch_try1987_11_21,allNYTSearch_try1989_11_29,allNYTSearch_try1990_11_04,allNYTSearch_try1992_11_29,allNYTSearch_try1994_11_27,allNYTSearch_try1996_02_26,allNYTSearch_try1998_01_14, allNYTSearch_try1999_12_27,allNYTSearch_try2001_10_10, allNYTSearch_try2003_01_01, allNYTSearch_try2004_11_21, allNYTSearch_try2006_01_01, allNYTSearch_try2006_05_04, allNYTSearch_try2006_06_18, allNYTSearch_try2007_02_01, allNYTSearch_try2007_06_27, allNYTSearch_try2008_04_25, allNYTSearch_try2008_10_14, allNYTSearch_try2009_11_23, allNYTSearch_try2010_04_30, allNYTSearch_try2011_12_01, allNYTSearch_try2013_06_01, allNYTSearch_try2014_12_10, allNYTSearch_try2015_11_11, allNYTSearch_try2016_06_16, allNYTSearch_try2017_01_26, allNYTSearch_try2017_09_19, allNYTSearch_try2018_11_30, allNYTSearch_try2019_12_31))
allNYTSearchtosave <- result_all_dfs
allNYTSearchtosave$response.docs.multimedia <- NULL
allNYTSearchtosave$response.docs.keywords <- NULL
allNYTSearchtosave$response.docs.byline.person<- NULL
#write.xlsx(allNYTSearch, 'allNYTSearch2012-2019-1459hits.xlsx')
write.table(allNYTSearchtosave, "allNYTSearch1980to2020.txt", sep="\t")
View(result_all_dfs)
funct_remove_rows<- function(dataFrame,col_dataframe){
not_news_variable <- c("Interactive Feature", "Review", "Letter", "Correction","List")
allNYTSearch_OnlyNews<<-dataFrame[!grepl(paste(not_news_variable, collapse="|"), col_dataframe),]
return(allNYTSearch_OnlyNews)
}
View(result_all_dfs)
#Getting rid of white spaces
#verify that this is right
```{r}
result_all_dfs_copy <-result_all_dfs
#Getting rid of white spaces
#verify that this is right
```{r}
library(sentimentr)
library(qdap)
library(jsonlite)
library(dplyr)
library(ggplot2)
library(tm)
library(tidyverse)
library(SentimentAnalysis)
library(quanteda)
library(xlsx)
#Getting rid of white spaces
#verify that this is right
```{r}
#Getting rid of white spaces
#verify that this is right
```{r}
#Getting rid of white spaces
#verify that this is right
```{r}
#Getting rid of white spaces
#verify that this is right
result_all_dfs_copy$response.docs.lead_paragraph <-(str_squish(result_all_dfs_copy$response.docs.lead_paragraph))
myCorpus <- Corpus(VectorSource(result_all_dfs_copy$response.docs.lead_paragraph))
dtm_NYTArticles <-  DocumentTermMatrix(myCorpus,
control =
list(removePunctuation = TRUE,
stopwords = TRUE,
tolower = TRUE,
removeNumbers = TRUE))
library(dplyr)
library(tidytext)
ap_td <- tidy(dtm_NYTArticles)
ap_sentiments <- ap_td %>%
inner_join(get_sentiments("bing"), by = c(term = "word"))
sentiment_scoreLM_cleancode<- analyzeSentiment(dtm_NYTArticles,
rules=list("SentimentLM"=list(ruleSentiment, loadDictionaryLM())))
View(ap_td)
